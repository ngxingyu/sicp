[{"id":"/sicpjs/1.2.3","tag":"TITLE","body":"1.2.3  Orders of Growth"},{"tag":"TEXT","id":"#p1","child":[{"body":"\n    The previous examples illustrate that processes can differ\n    considerably in the rates at which they consume computational\n    resources.  One convenient way to describe this difference is to use\n    the notion of \n    ","tag":"#text"},{"tag":"EM","child":[{"body":"order of growth","tag":"#text"}]},{"body":" to obtain a gross measure of the\n    \n    resources required by a process as the inputs become larger.\n  ","tag":"#text"}]},{"tag":"TEXT","id":"#p2","child":[{"body":"\n    Let ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":" be a parameter that measures the size of\n    the problem,  and let ","tag":"#text"},{"body":"$R(n)$","tag":"LATEX"},{"body":" be the amount \n    of resources the process requires for a problem of size\n    ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":".  In our previous examples we took \n    ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":" to be the number for which a given\n    function is to be computed, but there are other possibilities.\n    For instance, if our goal is to compute an approximation to the\n    square root of a number, we might take \n    ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":" to be the number of digits accuracy required.\n    For matrix multiplication we might take ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":" to\n    be the number of rows in the matrices. In general there are a number of\n    properties of the problem with respect to which it will be desirable to\n    analyze a given process. Similarly, ","tag":"#text"},{"body":"$R(n)$","tag":"LATEX"},{"body":"\n    might measure the number of internal storage registers used, the\n    number of elementary machine operations performed, and so on.  In\n    computers that do only a fixed number of operations at a time, the\n    time required will be proportional to the number of elementary machine\n    operations performed.\n  ","tag":"#text"}]},{"tag":"TEXT","id":"#p3","child":[{"body":"\n    We say that ","tag":"#text"},{"body":"$R(n)$","tag":"LATEX"},{"body":" has order of growth\n    ","tag":"#text"},{"body":"$\\Theta(f(n))$","tag":"LATEX"},{"body":", written\n    ","tag":"#text"},{"body":"$R(n)=\\Theta(f(n))$","tag":"LATEX"},{"body":" (pronounced\n    \"theta of \"), if there are\n    positive constants ","tag":"#text"},{"body":"$k_1$","tag":"LATEX"},{"body":" and\n    ","tag":"#text"},{"body":"$k_2$","tag":"LATEX"},{"body":" independent of\n    ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":" such that\n    ","tag":"#text"},{"body":"\n      \\[\n      \\begin{array}{lllll}\n      k_1\\,f(n) & \\leq & R(n) & \\leq & k_2\\,f(n)\n      \\end{array}\n      \\]\n    ","tag":"LATEX"},{"body":"\n    for any sufficiently large value of ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":".\n    (In other words, for large ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":", \n    the value ","tag":"#text"},{"body":"$R(n)$","tag":"LATEX"},{"body":" is sandwiched between \n    ","tag":"#text"},{"body":"$k_1f(n)$","tag":"LATEX"},{"body":" and\n    ","tag":"#text"},{"body":"$k_2f(n)$","tag":"LATEX"},{"body":".)\n  ","tag":"#text"}]},{"tag":"TEXT","id":"#p4","child":[{"body":"\n    For instance, with the linear recursive process for computing factorial\n    described in section ","tag":"#text"},{"tag":"REF","body":"1.2.1","href":"/sicpjs/1.2.1"},{"body":" the\n    number of steps grows proportionally to the input\n    ","tag":"#text"},{"body":"$n$","tag":"LATEX"},{"body":".  Thus, the steps required for this process\n    grows as ","tag":"#text"},{"body":"$\\Theta(n)$","tag":"LATEX"},{"body":".  We also saw that the space\n    required grows as ","tag":"#text"},{"body":"$\\Theta(n)$","tag":"LATEX"},{"body":". For the \n    \n    iterative factorial, the number of steps is still\n    ","tag":"#text"},{"body":"$\\Theta(n)$","tag":"LATEX"},{"body":" but the space is\n    ","tag":"#text"},{"body":"$\\Theta(1)$","tag":"LATEX"},{"body":"—that is, \n    constant.","tag":"#text"},{"tag":"FOOTNOTE_REF","id":"#footnote-link-1","body":"1","href":"/sicpjs/1.2.3#footnote-1"},{"body":" \n    The \n    \n    tree-recursive Fibonacci computation requires\n    ","tag":"#text"},{"body":"$\\Theta(\\phi^{n})$","tag":"LATEX"},{"body":" steps and space \n    ","tag":"#text"},{"body":"$\\Theta(n)$","tag":"LATEX"},{"body":", where\n    ","tag":"#text"},{"body":"$\\phi$","tag":"LATEX"},{"body":" is the golden ratio described in\n    section ","tag":"#text"},{"tag":"REF","body":"1.2.2","href":"/sicpjs/1.2.2"},{"body":".\n  ","tag":"#text"}]},{"tag":"TEXT","id":"#p5","child":[{"body":"\n    Orders of growth provide only a crude description of the behavior of a\n    process.  For example, a process requiring ","tag":"#text"},{"body":"$n^2$","tag":"LATEX"},{"body":"\n    steps and a process requiring ","tag":"#text"},{"body":"$1000n^2$","tag":"LATEX"},{"body":" steps and\n    a process requiring ","tag":"#text"},{"body":"$3n^2+10n+17$","tag":"LATEX"},{"body":" steps all have\n    ","tag":"#text"},{"body":"$\\Theta(n^2)$","tag":"LATEX"},{"body":" order of growth.  On the other hand,\n    order of growth provides a useful indication of how we may expect the\n    behavior of the process to change as we change the size of the problem.\n    For a\n    ","tag":"#text"},{"body":"$\\Theta(n)$","tag":"LATEX"},{"body":" (linear) process, doubling the size\n    will roughly double the amount of resources used.  For an \n    \n    exponential process, each increment in problem size will multiply the\n    resource utilization by a constant factor.  In the remainder of\n    section ","tag":"#text"},{"tag":"REF","body":"1.2","href":"/sicpjs/1.2"},{"body":"\n    we will examine two algorithms whose order of growth is \n    \n    logarithmic, so that doubling the problem size increases the resource\n    requirement by a constant amount.\n    ","tag":"#text"}]},{"tag":"EXERCISE","title":"Exercise 1.14","id":"#ex-1.14","child":[{"body":"\n    The sine of an angle (specified in radians) can be computed by making use\n    of the approximation ","tag":"#text"},{"body":"$\\sin x\\approx x$","tag":"LATEX"},{"body":"\n    if ","tag":"#text"},{"body":"$x$","tag":"LATEX"},{"body":" is sufficiently small, and the\n    trigonometric identity \n    ","tag":"#text"},{"body":"\n      \\[\n      \\begin{array}{lll}\n      \\sin x &=& 3\\sin {\\dfrac{x}{3}}-4\\sin^3{\\dfrac{x}{3}}\n      \\end{array}\n      \\]\n    ","tag":"LATEX"},{"body":"\n    to reduce the size of the argument of ","tag":"#text"},{"body":"$\\sin$","tag":"LATEX"},{"body":".\n    (For purposes of this exercise an angle is considered \"sufficiently\n    small\" if its magnitude is not greater than 0.1 radians.) These\n    ideas are incorporated in the following \n    functions:","tag":"#text"},{"tag":"SNIPPET","latex":false,"id":1,"eval":true,"prependLength":5,"program":"chap=1&prgrm=PTAEGUEkGEAVQFLlARgHQCY0GYBQuAzAVwDsBjAFwEsB7E0AQwCMBnACgA8BKUAb11CDQAJwCmFIsPodQAPgC8oAAygA-KBkAuUAFoNAblwBffMXLU6oMkSajOPfkJHjJ00ACoNHg8cKlKtPQADvZ8AkJiElKg2N4yegAs3ta29oYmZgGWLFQkdgwkAOYANqIO4YKRrqAAhKBszOwFJWVyymgoXBVOTurNpd09gtohOXkNRaWgYNhcXOn4Y3YAtgwUABYA+rCQ06AY80A","body":"function cube(x) {\n    return x * x * x;\n}\nfunction p(x) {\n    return 3 * x - 4 * cube(x);\n}\nfunction sine(angle) {\n    return ! (abs(angle) > 0.1)\n           ? angle\n           : p(sine(angle / 3));\n} "},{"tag":"OL","child":[{"tag":"LI","child":[{"body":"How many times is the\n      function","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"p"},{"body":" \n      applied when\n      ","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"sine(12.15)"},{"body":"\n      is evaluated?\n      ","tag":"#text"}]},{"tag":"LI","child":[{"body":"\n        What is the order of growth in space and number of steps (as a function\n\tof ","tag":"#text"},{"body":"$a$","tag":"LATEX"},{"body":") used by the process generated\n\tby the ","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"sine"},{"body":"function\n\twhen\n\t","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"sine(a)"},{"body":"\n\tis evaluated?\n      ","tag":"#text"}]}]}],"solution":[{"tag":"TEXT","id":"#p6","child":[{"tag":"OL","child":[{"tag":"LI","child":[{"body":" The function ","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"p"},{"body":"\n\t  will call itself recursively as long as the angle value is greater\n\t  than 0.1. There will be altogether 5 calls of\n\t  ","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"p"},{"body":", with arguments 12.15, 4.05,\n\t  1.35, 0.45, 0.15 and 0.05.\n\t  ","tag":"#text"}]},{"tag":"LI","child":[{"body":"\n\t    The function ","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"sine"},{"body":" gives\n\t    rise to a recursive process. In each recursive call, the\n\t    ","tag":"#text"},{"tag":"JAVASCRIPTINLINE","body":"angle"},{"body":" is divided by 3\n\t    until its absolute value is smaller than 0.1. \n\t    Thus the number of steps and the space required has an order\n\t    of growth of $O(\\log a)$. Note that the base of the logarithm\n\t    is immaterial for the order of growth because the logarithms\n\t    of different bases differ only by a constant factor.\n\t  ","tag":"#text"}]}]}]}]},{"tag":"DISPLAYFOOTNOTE","id":"#footnote-1","count":1,"href":"/sicpjs/1.2.3#footnote-link-1","child":[{"body":"These statements mask a great deal of oversimplification.\n    For instance, if we count process steps as \"machine operations\"\n    we are making the assumption that the number of machine operations needed to\n    perform, say, a multiplication is independent of the size of the numbers to\n    be multiplied, which is false if the numbers are sufficiently large.\n    Similar remarks hold for the estimates of space.  Like the design and\n    description of a process, the analysis of a process can be carried out at\n    various levels of abstraction.","tag":"#text"}]}]